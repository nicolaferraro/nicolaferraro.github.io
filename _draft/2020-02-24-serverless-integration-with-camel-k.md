---
title:  "Serverless Integration with Camel K"
modified: 2020-02-24 12:30:00 +0100
last_modified_at: 2020-02-24 12:30:00 +0100
tags: [Knative, Apache Camel, Openshift, Kubernetes, Serverless, JBoss Fuse]
categories: [Dev]
header:
    image: post-logo-apache-camel-k-native.png
    teaser: post-logo-apache-camel-k-native.png
---

Apache Camel K has made a huge leap since its inception and we're now proud to announce the 1.0.0 release.
We've been working hard in the last months to add more awesome features to Camel K, but also to improve its stability
and performance. This post contains a list of cool stuff that you'll find in latest release.

First of all, if you're living under a rock and it's the first time you hear about Camel K, 
you can read some introductory blog posts here ([1](/2018/10/15/introducing-camel-k/), [2](/2018/10/15/camel-k-on-knative/))
or look at the [new Apache Camel website](https://camel.apache.org/) that contains a [Camel K section](https://camel.apache.org/camel-k/latest/)
with a lot of material that is automatically generated from the [Github repository](https://github.com/apache/camel-k).

## IDE integration

Camel K development style is minimalistic: you need just to write a single file with your integration routes and you can immediately 
run them on any Kubernetes cluster. This way of defining things is common to many FaaS platforms (although Camel K is not a proper FaaS platform, 
but a lightweight *integration* platform) and it's technically difficult to provide IDE support, such as code completion and other utilities, 
to developers.

But now we've it. The Red Hat Integration tooling team has created some cool extensions for VS Code that make the development experience 
with Camel K even more exciting. 
You don't need to remember the Camel DSL syntax, the IDE will give you suggestions and error highlighting.

Code completion works with Java code, but it's not only limited to it: you also have suggestions and documentation out of the box when writing the Camel URIs and property files.
And you also have many options to run integrations and interact with them, all integrated in the IDE.

Just install the VS Code [Extension Pack for Apache Camel by Red Hat](https://marketplace.visualstudio.com/items?itemName=redhat.apache-camel-extension-pack) to have all these  features available.

## Serverless

Serverless is the most important area where we're focusing the new developments in Apache Camel K, although, you should remember it, 
you can have a wonderful Camel K experience even without serverless features.
To enable the serverless profile in Camel K, you just need to have [Knative](https://knative.dev) installed.

In recent releases, we have added support for the most recent advancements in Knative, for example, Camel K is very well integrated 
with the **Knative event broker** and you can easily produce or consume event from it.

With 2 lines of code you can transfer events (e.g. generated by IoT devices) from your MQTT broker to the mesh:

*bridge.groovy*
```groovy
from('paho:mytopic?brokerUrl=tcp://broker-address:1883&clientId=knative-bridge')
  .to('knative:event/device-event')
```

Not kidding, you just need to write those two lines of code in a file and run it with `kamel run bridge.groovy` to 
push data into the Knative broker. And you can also scale the Integration out (*Integration* is a Kubernetes custom resource, `oc get integrations` to see all them)
to have a higher throughput. Scaling here is manual because the source of events is a MQTT broker (but we've plans to put [auto-scaling also in this scenario](https://github.com/apache/camel-k/issues/1107)).

Auto-scaling works really well when you want to react to some Knative events:

*listener.groovy*
```groovy
from('knative:event/device-event')
  .to('http://myhost/webhook/random-id')
``` 

This integration is configured to receive all events with *type=device-event* and scales automatically with the load because it is materialized into a [Knative Serving Service](https://knative.dev/docs/serving/spec/knative-api-specification-1.0/#service)
and automatically [subscribed to the Eventing Broker via a Trigger](https://knative.dev/docs/eventing/broker-trigger/).
It then receives a [CloudEvent](https://cloudevents.io/) when your IoT devices produce something and scales down to zero if there's no data coming.
You just need to create it (as before, just `kamel run listener.groovy`), all the remaining configuration is 
done dynamically by the Camel K operator.

We've added much more features for having a better integration with the Knative ecosystem and we've also fixed some compatibility and performance issues that were present 
in previous versions. The user experience is now much smoother.

If you are a Knative YAML developer (!), instead of using Camel K directly, you also have the option to use [Knative Camel Sources](https://knative.dev/docs/eventing/samples/apache-camel-source/)
which are part of the Knative release. They are wrappers for Camel K integrations that are compatible with all the tools used by Knative developers (such as the `kn` CLI or the OpenShift serverless console).
Sources in Knative can only push data into the various Knative endpoints, but not the other way around (i.e. they should not be used to publish data from Knative to the outside).
In Camel K you don't have this distinction: the Route is the fundamental building block of a Camel integration and you can do whatever you want with it. 

## Fast startup and low memory 

We cannot say we're serverless without mentioning the work that we're doing in improving the performance of Camel K integrations.

Starting from Camel 3.1.0 which is the default version used by Camel K 1.0.0, you can benefit from all improvements that have been made directly in the core to make it much more lightweight. Claus Ibsen has written a series of blog posts ([part 1](http://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core.html?m=1), [part 2](http://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core_30.html?m=1), [part 3](http://www.davsclaus.com/2020/02/apache-camel-31-more-camel-core.html?m=1)) to highlight what has been changed to reduce memory footprint and speedup the startup time, which is foundamental when running integrations in a serverless environment.

But improvements are not only limited to the Camel core: we're doing much more. Several months ago we've started a new subproject of Apache Camel named ["Camel Quarkus"](https://github.com/apache/camel-quarkus) with the goal of seamlessly running integrations on top of the Quarkus framework. As you probably know, Quarkus is able to reduce the memory footprint of Java applications and improve the startup time, because it moves much startup logic to the build phase. And Quarkus applications can be also compiled to a native binary, allowing a dramatic improvements in performance.

In Camel K 1.0.0 we support Camel Quarkus in JVM mode (just run integrations enabling the [Quarkus trait](https://camel.apache.org/camel-k/latest/traits/quarkus.html), with "kamel run -t quarkus.enabled=true myintegration.groovy"). The goal is to have also the in-cluster automatic native compilation soon, in one of next releases!

## Fast build time

Every application running on Kubernetes needs to refer to a container image, but in Camel K you only provide the integration DSL and the operator does what it takes to run it, including building images directly on the cluster.

The operator manages a pool of reusable container images and if you redeploy your integration code, it does try to reuse existing images from the pool rather than building a new one at each change, because it takes some time to build a new one. It was 1 minute at the beginning...

But Kubernetes is moving so fast that you cannot solve a problem once and forget about it, you need to take care of it continuously. It happened that some of our third party dependencies that we used for doing builds in "vanilla Kube" has slowly degraded in performance up to a point where Camel K user experience was highly affected.

We decided to revolutionize the build system in order to dramatically improve (again!) the build phase of Camel K integrations.

Build time can be be now measured in seconds. A bunch of seconds, most of the times. This is more than a simple improvement!

## Better CLI

The 'kamel' CLI is the main tool we provide to developers to run integrations. It's not mandatory: at the end, an Integration is a Kubernetes custom resources and you can manage it with any Kubernetes standard tool. But it adds a lot of value when used.

For example, if you're a Camel Java developer it's not super easy to remember the boilerplate that you have to write in order to instantiate a Camel route builder. Now you don't have to:

'''
kamel init Handler.java

'''

You get a Java file with all the boilerplate written for you and you just have to write your integration routes. It works also with all other languages: Groovy, XML, YAML, Kotlin and JavaScript.

It's not just that. Often Camel K developers need to add a lot of command line options to configure the final behavior of their integration. For example, you may want to add a custom library with the '-d' option or configure a trait with '-t'.
You now don't have to specify them every time, since you can "--save" the configuration:

'''
kamel run -d org.my:lib:1.0.0 -t prometheus.enabled=true Routes.java --save
'''

The 'save' option executes the command and also saves the options into a 'kamel-config.yaml' file, to reuse them next time you run the integration, simply writing:
'''
kamel run Routes.java
'''

The other options are taken automatically from the config. You should only remember you have one to understand what flags you're passing.

The configuration is extremely useful in CI/CD scenarios because it provides a single place where you can store the whole configuration for all your integrations and reuse it across builds. If you're curious about the Ci/CD scenario, you can follow the [tutorial about Tekton pipelines](https://camel.apache.org/camel-k/latest/tutorials/tekton/tekton.html) to have more information.

## Master routes

Good old Camel users know why and when master routes are useful, but for those who are not familiar with the term, I'm going to provide a brief explanation.

Whenever you have an integration route that must be running, at any point in time, in at most one single Camel instance, you need to use a master route. Master routes can be declared by simply prefixing the consumer endpoint by the 'master' keyword and a name that will be used to create a named lock, e.g.

'''
from('master:lock:telegram:bots')
  .to('log:info')
'''

It can be used to print all messages that are sent to your Telegram bot. Since the Telegram API support a single consumer only, you can guard the route with a master prefix to have the guarantee that the consumer will be only one.

If you're wondering how there can be two instances running of you deploy one, well, think just to when you change your code and need to do a rolling update: for some time there'll be two pods running in parallel. Or you may want to embed a master route in a Knative autoscaling service: in this case, the service can scale autonomously based on the load, but there'll be only one telegram consumer at any time.

Master routes **work out of the box** in Camel K, you just need to purlt a prefix in your endpoint uri. A leader election protocol based on Kubernetes APIs resource locks will be automatically configured for you!

## CronJobs

All complex enough systems contain several scheduled jobs. This is especially true for that part of the system that handles integration with the outside.

Ideally, if you need to execute a quick periodic task, say, every two seconds, you would startup an integration with a route based on timer to execute the periodic task. E.g.

'''
from("timer:task?period=2s")
  .to(this, "businessLogic")
'''

But if the period between two executions, instead of 2 seconds ("2s" in the Camel URI) is 2 minutes ("2m") or 2 hours ("2h")?

You can see that keeping a container with a JVM running for a task that should be executed once every two minutes may be overkill. We live in a time where resources such as memory and CPU are really valuable.

So the Camel K operator automatically handles this situation by deploying your integration not as a Kubernetes deployment, but as a **CronJob**. This saves a lot of resources, especially when the period between executions is high. When it's time to run your integration code, a container starts, triggers the execution and then gracefully terminates. Everything is handled automatically by the Camel K runtime.

There are cases when you don't want this feature to be enabled, for example, when your code makes use of in memory caches that is better to keep between executions. In these cases, you can safely turn off the feature by passing the flag "-t cron.enabled=false" to the "kamel run" command.

The Cron feature does not only work with the "timer" component. We've also added a "cron" component to Camel 3.1 that works really well in combination with the cron trait.

